{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "LAYER_NM = 18\n",
    "path_data = './data'\n",
    "\n",
    "if not os.path.exists(path_data):\n",
    "    os.mkdir(path_data)\n",
    "\n",
    "transform_ = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]], std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "])\n",
    "train_data = datasets.STL10(root=path_data, split='train', download=True, transform=transform_)\n",
    "test_data = datasets.STL10(root=path_data, split='test', download=True, transform=transform_)\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(test_data,batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=True)\n",
    "\n",
    "# define classes\n",
    "classes = ['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "torch.Size([100, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_data))[0].size())\n",
    "print(next(iter(train_loader))[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockLower(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlockLower, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                            stride=stride, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockUpper(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlockUpper, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                            stride=stride, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, name, debugging=False, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.name = name\n",
    "        self.debugging = debugging\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            if self.name == 'resnet18':\n",
    "                layers.append(BasicBlockLower(self.in_planes, planes, stride))\n",
    "            else:\n",
    "                layers.append(BasicBlockUpper(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.debugging is True:\n",
    "            print('x:', x.size())\n",
    "        out = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), kernel_size=3, stride=2, padding=1)\n",
    "        if self.debugging is True:\n",
    "            print('start:', out.size())\n",
    "        out = self.layer1(out)\n",
    "        if self.debugging is True:\n",
    "            print('layer1 out:', out.size())\n",
    "        out = self.layer2(out)\n",
    "        if self.debugging is True:\n",
    "            print('layer2 out:', out.size())\n",
    "        out = self.layer3(out)\n",
    "        if self.debugging is True:\n",
    "            print('layer3 out:', out.size())\n",
    "        out = self.layer4(out)\n",
    "        if self.debugging is True:\n",
    "            print('layer4 out:', out.size())\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        if self.debugging is True:\n",
    "            print('avg_pool out:', out.size())\n",
    "        # out = out.view(out.size(0), -1)\n",
    "        out = self.flatten(out)\n",
    "        if self.debugging is True:\n",
    "            print('falten out:', out.size())\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet 18 <br/>\n",
    "x: torch.Size([100, 3, 128, 128]) <br/>\n",
    "start: torch.Size([100, 64, 128, 128]) <br/>\n",
    "layer1 out: torch.Size([100, 64, 128, 128]) <br/>\n",
    "layer2 out: torch.Size([100, 128, 64, 64]) <br/>\n",
    "layer3 out: torch.Size([100, 256, 32, 32]) <br/>\n",
    "layer4 out: torch.Size([100, 512, 16, 16]) <br/>\n",
    "avg_pool out: torch.Size([100, 512, 2, 2]) <br/>\n",
    "falten out: torch.Size([100, 2048])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Loss: 2.4557535\n",
      "epoch: 1, Loss: 1.8304498\n",
      "epoch: 2, Loss: 1.6796636\n",
      "epoch: 3, Loss: 1.564509\n",
      "epoch: 4, Loss: 1.5036189\n",
      "epoch: 5, Loss: 1.4410479\n",
      "epoch: 6, Loss: 1.3549792\n",
      "epoch: 7, Loss: 1.2628156\n",
      "epoch: 8, Loss: 1.1882302\n",
      "epoch: 9, Loss: 1.1111456\n",
      "epoch: 10, Loss: 1.0045026\n",
      "epoch: 11, Loss: 0.9176197\n",
      "epoch: 12, Loss: 0.8018226\n",
      "epoch: 13, Loss: 0.6786485\n",
      "epoch: 14, Loss: 0.5572389\n",
      "epoch: 15, Loss: 0.446047\n",
      "epoch: 16, Loss: 0.3560451\n",
      "epoch: 17, Loss: 0.2670573\n",
      "epoch: 18, Loss: 0.2048811\n",
      "epoch: 19, Loss: 0.1880614\n",
      "epoch: 20, Loss: 0.1442785\n",
      "epoch: 21, Loss: 0.0983283\n",
      "epoch: 22, Loss: 0.0984912\n",
      "epoch: 23, Loss: 0.0559359\n",
      "epoch: 24, Loss: 0.0487518\n",
      "epoch: 25, Loss: 0.0604478\n",
      "epoch: 26, Loss: 0.0827655\n",
      "epoch: 27, Loss: 0.05106\n",
      "epoch: 28, Loss: 0.0320918\n",
      "epoch: 29, Loss: 0.0214388\n",
      "epoch: 30, Loss: 0.0531115\n",
      "epoch: 31, Loss: 0.0452004\n",
      "epoch: 32, Loss: 0.0479321\n",
      "epoch: 33, Loss: 0.0369598\n",
      "epoch: 34, Loss: 0.0199866\n",
      "epoch: 35, Loss: 0.0128721\n",
      "epoch: 36, Loss: 0.025162\n",
      "epoch: 37, Loss: 0.0416438\n",
      "epoch: 38, Loss: 0.0963934\n",
      "epoch: 39, Loss: 0.0752816\n",
      "epoch: 40, Loss: 0.0444479\n",
      "epoch: 41, Loss: 0.0275973\n",
      "epoch: 42, Loss: 0.012237\n",
      "epoch: 43, Loss: 0.0096185\n",
      "epoch: 44, Loss: 0.0136058\n",
      "epoch: 45, Loss: 0.0244248\n",
      "epoch: 46, Loss: 0.0490138\n",
      "epoch: 47, Loss: 0.0833808\n",
      "epoch: 48, Loss: 0.0343973\n",
      "epoch: 49, Loss: 0.0167983\n",
      "epoch: 50, Loss: 0.0056132\n",
      "epoch: 51, Loss: 0.0019671\n",
      "epoch: 52, Loss: 0.001549\n",
      "epoch: 53, Loss: 0.0008923\n",
      "epoch: 54, Loss: 0.000756\n",
      "epoch: 55, Loss: 0.000595\n",
      "epoch: 56, Loss: 0.0007122\n",
      "epoch: 57, Loss: 0.0006232\n",
      "epoch: 58, Loss: 0.0006261\n",
      "epoch: 59, Loss: 0.0005335\n",
      "epoch: 60, Loss: 0.0006238\n",
      "epoch: 61, Loss: 0.0004632\n",
      "epoch: 62, Loss: 0.0003418\n",
      "epoch: 63, Loss: 0.0003267\n",
      "epoch: 64, Loss: 0.0003272\n",
      "epoch: 65, Loss: 0.0003166\n",
      "epoch: 66, Loss: 0.0003513\n",
      "epoch: 67, Loss: 0.0003765\n",
      "epoch: 68, Loss: 0.0003045\n",
      "epoch: 69, Loss: 0.0002837\n",
      "epoch: 70, Loss: 0.0002719\n",
      "epoch: 71, Loss: 0.0002687\n",
      "epoch: 72, Loss: 0.0002052\n",
      "epoch: 73, Loss: 0.0002391\n",
      "epoch: 74, Loss: 0.000251\n",
      "epoch: 75, Loss: 0.0002138\n",
      "epoch: 76, Loss: 0.0002022\n",
      "epoch: 77, Loss: 0.0002241\n",
      "epoch: 78, Loss: 0.0002585\n",
      "epoch: 79, Loss: 0.0002397\n",
      "epoch: 80, Loss: 0.0001756\n",
      "epoch: 81, Loss: 0.0002118\n",
      "epoch: 82, Loss: 0.0002088\n",
      "epoch: 83, Loss: 0.0002226\n",
      "epoch: 84, Loss: 0.0001481\n",
      "epoch: 85, Loss: 0.0001646\n",
      "epoch: 86, Loss: 0.0001666\n",
      "epoch: 87, Loss: 0.0001615\n",
      "epoch: 88, Loss: 0.0001389\n",
      "epoch: 89, Loss: 0.0001402\n",
      "epoch: 90, Loss: 0.0001462\n",
      "epoch: 91, Loss: 0.0001188\n",
      "epoch: 92, Loss: 0.0003046\n",
      "epoch: 93, Loss: 0.0001483\n",
      "epoch: 94, Loss: 0.0001567\n",
      "epoch: 95, Loss: 0.0001537\n",
      "epoch: 96, Loss: 0.0001201\n",
      "epoch: 97, Loss: 0.0001429\n",
      "epoch: 98, Loss: 0.0001361\n",
      "epoch: 99, Loss: 0.000153\n",
      "epoch: 100, Loss: 9.46e-05\n",
      "epoch: 101, Loss: 0.0001113\n",
      "epoch: 102, Loss: 0.0001193\n",
      "epoch: 103, Loss: 0.0001103\n",
      "epoch: 104, Loss: 0.000145\n",
      "epoch: 105, Loss: 9.46e-05\n",
      "epoch: 106, Loss: 0.0001112\n",
      "epoch: 107, Loss: 9.13e-05\n",
      "epoch: 108, Loss: 9.72e-05\n",
      "epoch: 109, Loss: 0.0001123\n",
      "epoch: 110, Loss: 8.03e-05\n",
      "epoch: 111, Loss: 0.0001226\n",
      "epoch: 112, Loss: 8.98e-05\n",
      "epoch: 113, Loss: 0.0001153\n",
      "epoch: 114, Loss: 0.0001223\n",
      "epoch: 115, Loss: 0.0001189\n",
      "epoch: 116, Loss: 0.0001308\n",
      "epoch: 117, Loss: 9.91e-05\n",
      "epoch: 118, Loss: 0.0001324\n",
      "epoch: 119, Loss: 9.16e-05\n",
      "epoch: 120, Loss: 0.0001202\n",
      "epoch: 121, Loss: 9.54e-05\n",
      "epoch: 122, Loss: 9.6e-05\n",
      "epoch: 123, Loss: 9.61e-05\n",
      "epoch: 124, Loss: 8.9e-05\n",
      "epoch: 125, Loss: 0.0001131\n",
      "epoch: 126, Loss: 0.0001074\n",
      "epoch: 127, Loss: 8.6e-05\n",
      "epoch: 128, Loss: 0.0001112\n",
      "epoch: 129, Loss: 7.85e-05\n",
      "epoch: 130, Loss: 7.24e-05\n",
      "epoch: 131, Loss: 7.49e-05\n",
      "epoch: 132, Loss: 0.0001098\n",
      "epoch: 133, Loss: 9.17e-05\n",
      "epoch: 134, Loss: 0.0001426\n",
      "epoch: 135, Loss: 7.15e-05\n",
      "epoch: 136, Loss: 9.63e-05\n",
      "epoch: 137, Loss: 0.0001118\n",
      "epoch: 138, Loss: 7.97e-05\n",
      "epoch: 139, Loss: 0.0001141\n",
      "epoch: 140, Loss: 8.25e-05\n",
      "epoch: 141, Loss: 0.000102\n",
      "epoch: 142, Loss: 7.81e-05\n",
      "epoch: 143, Loss: 8.77e-05\n",
      "epoch: 144, Loss: 9.19e-05\n",
      "epoch: 145, Loss: 7.76e-05\n",
      "epoch: 146, Loss: 7.65e-05\n",
      "epoch: 147, Loss: 7.51e-05\n",
      "epoch: 148, Loss: 0.0001074\n",
      "epoch: 149, Loss: 9e-05\n",
      "epoch: 150, Loss: 9.1e-05\n",
      "epoch: 151, Loss: 7.06e-05\n",
      "epoch: 152, Loss: 9.51e-05\n",
      "epoch: 153, Loss: 8.3e-05\n",
      "epoch: 154, Loss: 7.53e-05\n",
      "epoch: 155, Loss: 9.73e-05\n",
      "epoch: 156, Loss: 9.47e-05\n",
      "epoch: 157, Loss: 8.94e-05\n",
      "epoch: 158, Loss: 6.83e-05\n",
      "epoch: 159, Loss: 7.81e-05\n",
      "epoch: 160, Loss: 9.27e-05\n",
      "epoch: 161, Loss: 9.39e-05\n",
      "epoch: 162, Loss: 0.0001071\n",
      "epoch: 163, Loss: 8.31e-05\n",
      "epoch: 164, Loss: 9.44e-05\n",
      "epoch: 165, Loss: 9e-05\n",
      "epoch: 166, Loss: 7.65e-05\n",
      "epoch: 167, Loss: 8.18e-05\n",
      "epoch: 168, Loss: 9.14e-05\n",
      "epoch: 169, Loss: 0.0001006\n",
      "epoch: 170, Loss: 8.31e-05\n",
      "epoch: 171, Loss: 7.4e-05\n",
      "epoch: 172, Loss: 9.06e-05\n",
      "epoch: 173, Loss: 0.0001075\n",
      "epoch: 174, Loss: 6.88e-05\n",
      "epoch: 175, Loss: 6.65e-05\n",
      "epoch: 176, Loss: 7.46e-05\n",
      "epoch: 177, Loss: 7.89e-05\n",
      "epoch: 178, Loss: 8.32e-05\n",
      "epoch: 179, Loss: 8.48e-05\n",
      "epoch: 180, Loss: 9.67e-05\n",
      "epoch: 181, Loss: 8.26e-05\n",
      "epoch: 182, Loss: 8.46e-05\n",
      "epoch: 183, Loss: 8.03e-05\n",
      "epoch: 184, Loss: 8.18e-05\n",
      "epoch: 185, Loss: 9.07e-05\n",
      "epoch: 186, Loss: 8.78e-05\n",
      "epoch: 187, Loss: 8.49e-05\n",
      "epoch: 188, Loss: 6.98e-05\n",
      "epoch: 189, Loss: 8.71e-05\n",
      "epoch: 190, Loss: 8.74e-05\n",
      "epoch: 191, Loss: 7.33e-05\n",
      "epoch: 192, Loss: 8.4e-05\n",
      "epoch: 193, Loss: 8.5e-05\n",
      "epoch: 194, Loss: 6.1e-05\n",
      "epoch: 195, Loss: 0.0001008\n",
      "epoch: 196, Loss: 7.35e-05\n",
      "epoch: 197, Loss: 7.07e-05\n",
      "epoch: 198, Loss: 7.63e-05\n",
      "epoch: 199, Loss: 7.65e-05\n",
      "epoch: 200, Loss: 7.85e-05\n",
      "epoch: 201, Loss: 7.04e-05\n",
      "epoch: 202, Loss: 6.66e-05\n",
      "epoch: 203, Loss: 7.02e-05\n",
      "epoch: 204, Loss: 8.32e-05\n",
      "epoch: 205, Loss: 8.41e-05\n",
      "epoch: 206, Loss: 7.62e-05\n",
      "epoch: 207, Loss: 8.95e-05\n",
      "epoch: 208, Loss: 8.33e-05\n",
      "epoch: 209, Loss: 8.98e-05\n",
      "epoch: 210, Loss: 8.74e-05\n",
      "epoch: 211, Loss: 9.01e-05\n",
      "epoch: 212, Loss: 8.36e-05\n",
      "epoch: 213, Loss: 8.74e-05\n",
      "epoch: 214, Loss: 8.32e-05\n",
      "epoch: 215, Loss: 7.15e-05\n",
      "epoch: 216, Loss: 6.56e-05\n",
      "epoch: 217, Loss: 8.85e-05\n",
      "epoch: 218, Loss: 7.71e-05\n",
      "epoch: 219, Loss: 8.24e-05\n",
      "epoch: 220, Loss: 8.72e-05\n",
      "epoch: 221, Loss: 9.61e-05\n",
      "epoch: 222, Loss: 9.46e-05\n",
      "epoch: 223, Loss: 7.22e-05\n",
      "epoch: 224, Loss: 8.48e-05\n",
      "epoch: 225, Loss: 8.6e-05\n",
      "epoch: 226, Loss: 8.26e-05\n",
      "epoch: 227, Loss: 8.49e-05\n",
      "epoch: 228, Loss: 8.04e-05\n",
      "epoch: 229, Loss: 9.11e-05\n",
      "epoch: 230, Loss: 0.0001735\n",
      "epoch: 231, Loss: 7.02e-05\n",
      "epoch: 232, Loss: 6.76e-05\n",
      "epoch: 233, Loss: 7.67e-05\n",
      "epoch: 234, Loss: 7.62e-05\n",
      "epoch: 235, Loss: 6.81e-05\n",
      "epoch: 236, Loss: 7.74e-05\n",
      "epoch: 237, Loss: 8.9e-05\n",
      "epoch: 238, Loss: 8.96e-05\n",
      "epoch: 239, Loss: 0.0001086\n",
      "epoch: 240, Loss: 7.95e-05\n",
      "epoch: 241, Loss: 7.75e-05\n",
      "epoch: 242, Loss: 8.61e-05\n",
      "epoch: 243, Loss: 9.01e-05\n",
      "epoch: 244, Loss: 7.29e-05\n",
      "epoch: 245, Loss: 7.68e-05\n",
      "epoch: 246, Loss: 9.2e-05\n",
      "epoch: 247, Loss: 7.49e-05\n",
      "epoch: 248, Loss: 7.3e-05\n",
      "epoch: 249, Loss: 0.0001058\n",
      "epoch: 250, Loss: 9.57e-05\n",
      "epoch: 251, Loss: 7.42e-05\n",
      "epoch: 252, Loss: 6.95e-05\n",
      "epoch: 253, Loss: 8.27e-05\n",
      "epoch: 254, Loss: 7.99e-05\n",
      "epoch: 255, Loss: 7.65e-05\n",
      "epoch: 256, Loss: 0.0001071\n",
      "epoch: 257, Loss: 7.66e-05\n",
      "epoch: 258, Loss: 8e-05\n",
      "epoch: 259, Loss: 9.63e-05\n",
      "epoch: 260, Loss: 8.15e-05\n",
      "epoch: 261, Loss: 9.85e-05\n",
      "epoch: 262, Loss: 5.85e-05\n",
      "epoch: 263, Loss: 6.91e-05\n",
      "epoch: 264, Loss: 7.03e-05\n",
      "epoch: 265, Loss: 9.35e-05\n",
      "epoch: 266, Loss: 8.65e-05\n",
      "epoch: 267, Loss: 6.16e-05\n",
      "epoch: 268, Loss: 8.78e-05\n",
      "epoch: 269, Loss: 7.09e-05\n",
      "epoch: 270, Loss: 6.97e-05\n",
      "epoch: 271, Loss: 7.41e-05\n",
      "epoch: 272, Loss: 8.25e-05\n",
      "epoch: 273, Loss: 8.18e-05\n",
      "epoch: 274, Loss: 8.54e-05\n",
      "epoch: 275, Loss: 6.51e-05\n",
      "epoch: 276, Loss: 7.8e-05\n",
      "epoch: 277, Loss: 7.42e-05\n",
      "epoch: 278, Loss: 8.61e-05\n",
      "epoch: 279, Loss: 6.7e-05\n",
      "epoch: 280, Loss: 8.32e-05\n",
      "epoch: 281, Loss: 6.66e-05\n",
      "epoch: 282, Loss: 7.46e-05\n",
      "epoch: 283, Loss: 8.17e-05\n",
      "epoch: 284, Loss: 6.76e-05\n",
      "epoch: 285, Loss: 8.4e-05\n",
      "epoch: 286, Loss: 8.11e-05\n",
      "epoch: 287, Loss: 9.14e-05\n",
      "epoch: 288, Loss: 8.97e-05\n",
      "epoch: 289, Loss: 8.54e-05\n",
      "epoch: 290, Loss: 8.3e-05\n",
      "epoch: 291, Loss: 8.47e-05\n",
      "epoch: 292, Loss: 6.77e-05\n",
      "epoch: 293, Loss: 8.22e-05\n",
      "epoch: 294, Loss: 7.7e-05\n",
      "epoch: 295, Loss: 7.54e-05\n",
      "epoch: 296, Loss: 7.46e-05\n",
      "epoch: 297, Loss: 9.87e-05\n",
      "epoch: 298, Loss: 8.78e-05\n",
      "epoch: 299, Loss: 7.18e-05\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 1e-2\n",
    "model_d = next(iter(train_loader))[0].size()[-2] * next(iter(train_loader))[0].size()[-1]\n",
    "block_list = {'resnet18':[2,2,2,2], 'resnet34':[3,4,6,3], 'resnet50':[3,4,6,3], \n",
    "              'resnet101':[3,4,23,3], 'resnet152':[3,8,36,3]}\n",
    "y_dim = 10 # output class\n",
    "name = 'resnet18'\n",
    "model = ResNet(block_list[name], name, debugging=False).to(device)\n",
    "# model = ResNet(model_d, y_dim).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "df_loss = pd.DataFrame(columns=['loss'])\n",
    "epochs = 300\n",
    "batch_size = len(train_loader)\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    for image, label in train_loader:\n",
    "        x = image.to(device)\n",
    "        y = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = loss_func(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    df_loss.loc[i, 'loss'] = round(running_loss/batch_size, 4)\n",
    "    print(f'epoch: {i}, Loss:', round(running_loss/batch_size, 7))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.8304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.6797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss\n",
       "0    2.4558\n",
       "1    1.8304\n",
       "2    1.6797\n",
       "3    1.5645\n",
       "4    1.5036\n",
       "..      ...\n",
       "295  0.0001\n",
       "296  0.0001\n",
       "297  0.0001\n",
       "298  0.0001\n",
       "299  0.0001\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 62.75%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "test_result = pd.DataFrame(columns=['output', 'y'])\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, (input, label) in enumerate(test_loader):\n",
    "        x = input.to(device)\n",
    "        y = label.to(device)\n",
    "        outputs = model(x)\n",
    "        # value, pred = torch.max(outputs, 1)\n",
    "        pred = torch.argmax(outputs, 1)\n",
    "        out = pd.DataFrame(np.array([pred.detach().cpu().numpy(), y.detach().cpu().numpy()]).T, columns=['output', 'y'])\n",
    "        # print(out)\n",
    "        test_result = pd.concat([test_result, out], axis=0).reset_index(drop=True)\n",
    "\n",
    "        total += y.size(0)\n",
    "        correct += (torch.argmax(outputs, 1) == y).sum().item()\n",
    "        \n",
    "    print(\"test accuracy : {}%\".format((100 * correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     output  y\n",
       "0         6  6\n",
       "1         6  7\n",
       "2         3  5\n",
       "3         0  0\n",
       "4         3  3\n",
       "...     ... ..\n",
       "7995      2  9\n",
       "7996      6  6\n",
       "7997      8  8\n",
       "7998      9  8\n",
       "7999      8  8\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 5, ..., 8, 8, 8], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6275   Recall: 0.6275\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(list(test_result['y'].values), list(test_result['output'].values))\n",
    "rcll = recall_score(list(test_result['y'].values), list(test_result['output'].values), average='micro')\n",
    "print('Accuracy:', acc, '  Recall:', rcll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
